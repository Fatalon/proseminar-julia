# Parallel Computing

## Data Movement

## Global Variables
* calls may refer to global variables
* little bit different treated under module Main
* Variables globally created at 'workers != 1' continues to exist
**  New global bindings are created on destination workers if they are referenced as part of a remote call
** Global constants are declared as constants on remote nodes too
** Globals are re-sent to a destination worker only in the context of a remote call, and then only if its value has changed. Also, the cluster does not synchronize global bindings across nodes
* avoid referencing globals in remote calls
** use let blovks instead
** check with @spawnat

## Parallel Map and Loops
* parallel Computations which do not require data Movement
* many iterations independently with reduction in the end
** generally tensor-rank-reducing
** @parallel instead of @spawn (no limits of processes running)
*** @spawn as many as you wrote @spawn

[source,julia]
----
nheads = @parallel (+) for i = 1:200000000
    Int(rand(Bool))
end
----

* different behavior than serial for loops
** iterations do not happen in a specified order
** writes to variables will not be globally visible
** Any variables used inside the parallel loop will be copied and broadcast to each process
*** does not work as intended

[source,julia]
----
a = zeros(100000)
@parallel for i = 1:100000
    a[i] = i
end
----

* use shared Arrays instead
* outside variables (outer scope) perfectly reasonable if variables are read only

[source,julia]
----
a = randn(1000)
@parallel (+) for i = 1:100000
    f(a[rand(1:end)])
end
----

* reduction operator can be omitted if unnecessary
** loop executes then asynchronously
** or wait for completion at the end of the loop by prefixing it with @sync, like @sync @parallel for

### parallel map
* pmap()
* designed for where each function call does a large amount of work
* @parallel for can handle situations where each iteration is tiny
** such as summing two numbers
* pmap and @parallel for use just workers
* final reducation is done by the calling process

## Synchronization With Remote References

## Scheduling

* Tasks
** computations with possibility to be suspended and resumed later on
** possible to interrupt task by switching to other task
** differences to function calls:
*** no space used (does not consume call stack)
*** no order between finishing execution
** possibility to passing values back and forth as unnecessary without obvious caller or callee

* Channels
** waitable first in first out queue for multiple tasks writing and reading
** Channel can be used as an iterable object
** multiple tasks can be bound to a Channel and vice-versa
** can be created with bound task as argument, gets automatically closed when tasks terminates
** need to be closed before iterating


[source,julia]
----
function producer(c::Channel)
           put!(c, "start")
           for n=1:4
               put!(c, 2n)
           end
           put!(c, "stop")
       end;
for x in Channel(producer)
          println(x)
      end
----
@

## @Code_warntype
* good tool to identify bottlenecks
